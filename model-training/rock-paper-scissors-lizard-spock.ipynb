{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RockPaperScissorsLizardSpock.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will finetune a SqueezeNet pretrained on ImageNet to classify between the classes 'rock', 'paper', 'scissors', 'lizard', 'spock' and 'other'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should already be a folder for each class in `./data/train/`. E.g. all `rock` images should be in `./data/train/rock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "model_dir = data_dir + 'models/'\n",
    "train_dir = data_dir + 'train/'\n",
    "val_dir = data_dir + 'val/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the next cell should be (in any order) `['lizard', 'spock', 'other', 'paper', 'scissors', 'rock']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lizard', 'spock', 'other', 'paper', 'scissors', 'rock']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(train_dir)\n",
    "num_classes = len(classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a train/validation split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in classes:\n",
    "    os.makedirs(val_dir + c, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_val_split(p):\n",
    "    \"\"\"\n",
    "    Move random images of each category from train to val.\n",
    "    p is the percentage of images to move, e.g.\n",
    "    p == 0.2 will move 20% of each category to val.\n",
    "    \"\"\"\n",
    "    for c in classes:\n",
    "        file_names = os.listdir(train_dir + c)\n",
    "        permutation = np.random.permutation(file_names)\n",
    "        for i in range(int(len(file_names)*p)):\n",
    "            file_path = os.path.join(c, permutation[i])\n",
    "            os.rename(os.path.join(train_dir, file_path), \n",
    "                      os.path.join(val_dir, file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only do this once\n",
    "make_val_split(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, Dropout, Activation, GlobalAveragePooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SqueezeNet but replace its top layers (the classification layers) to classify between 'rock', 'paper', 'scissors', 'lizard', 'spock' and 'other' and not between the 1000 ImageNet classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    base_model = SqueezeNet(weights='imagenet', include_top=False, input_shape=(227,227,3))\n",
    "    x = base_model.output\n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "    x = Convolution2D(num_classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    predictions = Activation('softmax', name='predictions')(x)\n",
    "\n",
    "    return Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 227, 227, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 113, 113, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 113, 113, 64) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 56, 56, 16)   1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 56, 56, 16)   0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 56, 56, 64)   1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 56, 56, 64)   9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 56, 56, 64)   0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 56, 56, 64)   0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 56, 56, 128)  0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 56, 56, 16)   2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 56, 56, 16)   0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 56, 56, 64)   1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 56, 56, 64)   9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 56, 56, 64)   0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 56, 56, 64)   0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 56, 56, 128)  0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 27, 27, 128)  0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 27, 27, 32)   4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 27, 27, 32)   0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 27, 27, 128)  4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 27, 27, 128)  36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 27, 27, 128)  0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 27, 27, 128)  0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 27, 27, 256)  0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 27, 27, 32)   8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 27, 27, 32)   0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 27, 27, 128)  4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 27, 27, 128)  36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 27, 27, 128)  0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 27, 27, 128)  0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 27, 27, 256)  0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 13, 13, 256)  0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 13, 13, 48)   12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 13, 13, 48)   0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 13, 13, 192)  9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 13, 13, 192)  83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 13, 13, 192)  0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 13, 13, 192)  0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 13, 13, 384)  0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 13, 13, 48)   18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 13, 13, 48)   0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 13, 13, 192)  9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 13, 13, 192)  83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 13, 13, 192)  0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 13, 13, 192)  0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 13, 13, 384)  0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 13, 13, 64)   24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 13, 13, 64)   0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 13, 13, 256)  16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 13, 13, 256)  147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 13, 13, 256)  0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 13, 13, 256)  0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 13, 13, 512)  0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 13, 13, 64)   32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 13, 13, 64)   0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 13, 13, 256)  16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 13, 13, 256)  147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 13, 13, 256)  0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 13, 13, 256)  0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 13, 13, 512)  0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 13, 13, 512)  0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 13, 13, 6)    3078        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 13, 13, 6)    0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 6)            0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 6)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 725,574\n",
      "Trainable params: 725,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, generator=ImageDataGenerator(), shuffle=True,\n",
    "                batch_size=batch_size, class_mode='categorical', target_size=(227,227)):\n",
    "    return generator.flow_from_directory(dirname, shuffle=shuffle, batch_size=batch_size,\n",
    "                                 class_mode=class_mode, target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageDataGenerator will subtract the imagenet mean from each image and do some data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subtract_imagenet_mean(x):\n",
    "    x[..., 0] -= 103.939\n",
    "    x[..., 1] -= 116.779\n",
    "    x[..., 2] -= 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14177 images belonging to 6 classes.\n",
      "Found 3540 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=subtract_imagenet_mean,\n",
    "                                rotation_range=15, \n",
    "                                height_shift_range=0.1, \n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.1,\n",
    "                                width_shift_range=0.1)\n",
    "train_batches = get_batches(train_dir, generator=train_gen)\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=subtract_imagenet_mean)\n",
    "val_batches = get_batches(val_dir, generator=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = train_batches.samples\n",
    "num_val = val_batches.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(model, epochs):\n",
    "    model.fit_generator(train_batches, \n",
    "                        steps_per_epoch=num_train // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_batches,\n",
    "                        validation_steps=num_val // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "110/110 [==============================] - 121s - loss: 1.4623 - acc: 0.4243 - val_loss: 0.7275 - val_acc: 0.7428\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 112s - loss: 0.5796 - acc: 0.7931 - val_loss: 0.2845 - val_acc: 0.9051\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 111s - loss: 0.2812 - acc: 0.9047 - val_loss: 0.1186 - val_acc: 0.9618\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 111s - loss: 0.1971 - acc: 0.9349 - val_loss: 0.0925 - val_acc: 0.9714\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 111s - loss: 0.1276 - acc: 0.9574 - val_loss: 0.0526 - val_acc: 0.9826\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "fit(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "110/110 [==============================] - 121s - loss: 0.0934 - acc: 0.9701 - val_loss: 0.0675 - val_acc: 0.9792\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 111s - loss: 0.0812 - acc: 0.9751 - val_loss: 0.0310 - val_acc: 0.9902\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 111s - loss: 0.0718 - acc: 0.9762 - val_loss: 0.0552 - val_acc: 0.9841\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 111s - loss: 0.0588 - acc: 0.9813 - val_loss: 0.0141 - val_acc: 0.9954\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 111s - loss: 0.0463 - acc: 0.9853 - val_loss: 0.0137 - val_acc: 0.9954\n"
     ]
    }
   ],
   "source": [
    "fit(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "110/110 [==============================] - 120s - loss: 0.0489 - acc: 0.9837 - val_loss: 0.0220 - val_acc: 0.9907\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 111s - loss: 0.0461 - acc: 0.9851 - val_loss: 0.0076 - val_acc: 0.9983\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 111s - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0049 - val_acc: 0.9980\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 111s - loss: 0.0297 - acc: 0.9907 - val_loss: 0.0066 - val_acc: 0.9977\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 111s - loss: 0.0332 - acc: 0.9893 - val_loss: 0.0078 - val_acc: 0.9977\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "fit(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "110/110 [==============================] - 120s - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0041 - val_acc: 0.9980\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 111s - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0046 - val_acc: 0.9991\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 111s - loss: 0.0137 - acc: 0.9960 - val_loss: 0.0076 - val_acc: 0.9962\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 111s - loss: 0.0133 - acc: 0.9952 - val_loss: 0.0055 - val_acc: 0.9991\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 111s - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0050 - val_acc: 0.9977\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-6\n",
    "fit(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "110/110 [==============================] - 120s - loss: 0.0098 - acc: 0.9966 - val_loss: 0.0022 - val_acc: 0.9991\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 111s - loss: 0.0164 - acc: 0.9951 - val_loss: 0.0050 - val_acc: 0.9983\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 111s - loss: 0.0110 - acc: 0.9961 - val_loss: 0.0030 - val_acc: 0.9988\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 111s - loss: 0.0084 - acc: 0.9969 - val_loss: 0.0033 - val_acc: 0.9991\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 111s - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0033 - val_acc: 0.9986\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-7\n",
    "fit(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the weights for the case they are needed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(data_dir + 'models/keras-weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To load them do\n",
    "```python\n",
    "model.load_weights(data_dir + 'models/keras-weights.hdf5')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model and weights for deeplearn.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deeplearn.js repository provides the script `dump_checkpoint_vars.py` which takes a tensorflow checkpoint and converts it for use with deeplearn.js. To use this, we will first save the model as a tensorflow checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deeplearn.js this model will only be used for inference, no training will be done. So we have to tell keras to use the model in 'inference mode' where some layers behave differently (e.g. Dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has to be rebuilt for this to take effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "\n",
    "model = Model.from_config(config)\n",
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Save the checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/models/model.ckpt'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = K.get_session()\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, model_dir + 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a slightly modified version of `dump_checkpoint_vars.py` from deeplearn.js to convert the checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing variable fire6/expand3x3_1/bias as fire6/expand3x3/bias\n",
      "Writing variable fire6/expand3x3_1/kernel as fire6/expand3x3/kernel\n",
      "Ignoring Adam/beta_1\n",
      "Ignoring Adam/beta_2\n",
      "Writing variable fire7/expand1x1_1/bias as fire7/expand1x1/bias\n",
      "Writing variable fire7/expand1x1_1/kernel as fire7/expand1x1/kernel\n",
      "Writing variable fire7/squeeze1x1_1/bias as fire7/squeeze1x1/bias\n",
      "Writing variable fire7/squeeze1x1_1/kernel as fire7/squeeze1x1/kernel\n",
      "Writing variable fire9/expand1x1_1/bias as fire9/expand1x1/bias\n",
      "Writing variable fire9/expand1x1_1/kernel as fire9/expand1x1/kernel\n",
      "Ignoring training/Adam/Variable_98\n",
      "Ignoring training/Adam/Variable_99\n",
      "Writing variable fire6/squeeze1x1_1/bias as fire6/squeeze1x1/bias\n",
      "Writing variable fire6/squeeze1x1_1/kernel as fire6/squeeze1x1/kernel\n",
      "Writing variable fire2/expand3x3_1/bias as fire2/expand3x3/bias\n",
      "Writing variable fire2/expand3x3_1/kernel as fire2/expand3x3/kernel\n",
      "Writing variable fire8/squeeze1x1_1/bias as fire8/squeeze1x1/bias\n",
      "Writing variable fire8/squeeze1x1_1/kernel as fire8/squeeze1x1/kernel\n",
      "Writing variable fire8/expand3x3_1/bias as fire8/expand3x3/bias\n",
      "Writing variable fire8/expand3x3_1/kernel as fire8/expand3x3/kernel\n",
      "Writing variable fire3/expand1x1_1/bias as fire3/expand1x1/bias\n",
      "Writing variable fire3/expand1x1_1/kernel as fire3/expand1x1/kernel\n",
      "Writing variable fire3/expand3x3_1/bias as fire3/expand3x3/bias\n",
      "Writing variable fire3/expand3x3_1/kernel as fire3/expand3x3/kernel\n",
      "Writing variable fire5/expand3x3_1/bias as fire5/expand3x3/bias\n",
      "Writing variable fire5/expand3x3_1/kernel as fire5/expand3x3/kernel\n",
      "Writing variable fire3/squeeze1x1_1/bias as fire3/squeeze1x1/bias\n",
      "Writing variable fire3/squeeze1x1_1/kernel as fire3/squeeze1x1/kernel\n",
      "Writing variable fire7/expand3x3_1/bias as fire7/expand3x3/bias\n",
      "Writing variable fire7/expand3x3_1/kernel as fire7/expand3x3/kernel\n",
      "Writing variable fire2/squeeze1x1_1/bias as fire2/squeeze1x1/bias\n",
      "Writing variable fire2/squeeze1x1_1/kernel as fire2/squeeze1x1/kernel\n",
      "Writing variable fire4/squeeze1x1_1/bias as fire4/squeeze1x1/bias\n",
      "Writing variable fire4/squeeze1x1_1/kernel as fire4/squeeze1x1/kernel\n",
      "Writing variable fire2/expand1x1_1/bias as fire2/expand1x1/bias\n",
      "Writing variable fire2/expand1x1_1/kernel as fire2/expand1x1/kernel\n",
      "Writing variable fire4/expand3x3_1/bias as fire4/expand3x3/bias\n",
      "Writing variable fire4/expand3x3_1/kernel as fire4/expand3x3/kernel\n",
      "Writing variable fire8/expand1x1_1/bias as fire8/expand1x1/bias\n",
      "Writing variable fire8/expand1x1_1/kernel as fire8/expand1x1/kernel\n",
      "Writing variable fire9/expand3x3_1/bias as fire9/expand3x3/bias\n",
      "Writing variable fire9/expand3x3_1/kernel as fire9/expand3x3/kernel\n",
      "Writing variable fire5/squeeze1x1_1/bias as fire5/squeeze1x1/bias\n",
      "Writing variable fire5/squeeze1x1_1/kernel as fire5/squeeze1x1/kernel\n",
      "Writing variable fire6/expand1x1_1/bias as fire6/expand1x1/bias\n",
      "Writing variable fire6/expand1x1_1/kernel as fire6/expand1x1/kernel\n",
      "Writing variable conv1_1/bias as conv1/bias\n",
      "Writing variable conv1_1/kernel as conv1/kernel\n",
      "Writing variable conv10_1/bias as conv10/bias\n",
      "Writing variable conv10_1/kernel as conv10/kernel\n",
      "Writing variable fire9/squeeze1x1_1/bias as fire9/squeeze1x1/bias\n",
      "Writing variable fire9/squeeze1x1_1/kernel as fire9/squeeze1x1/kernel\n",
      "Writing variable fire5/expand1x1_1/bias as fire5/expand1x1/bias\n",
      "Writing variable fire5/expand1x1_1/kernel as fire5/expand1x1/kernel\n",
      "Writing variable fire4/expand1x1_1/bias as fire4/expand1x1/bias\n",
      "Writing variable fire4/expand1x1_1/kernel as fire4/expand1x1/kernel\n",
      "Writing manifest to deeplearn-checkpoint_no-invert/manifest.json\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%run dump_checkpoint_vars.py --output_dir=deeplearn-checkpoint \\\n",
    "--checkpoint_file=data/models/model.ckpt \\\n",
    "--remove_variables_regex training*|Adam*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have created the folder `deeplearn-checkpoint` in the current directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
