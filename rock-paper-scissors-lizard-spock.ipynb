{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RockPaperScissorsLizardSpock.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will finetune a SqueezeNet pretrained on ImageNet to classify between the classes 'rock', 'paper', 'scissors', 'lizard', 'spock' and 'other'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There should already be a folder for each class in `./data/train/`. E.g. all `rock` images should be in `./data/train/rock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "train_dir = data_dir + 'train/'\n",
    "val_dir = data_dir + 'val/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The output of the next cell should be (in any order) `['lizard', 'spock', 'other', 'paper', 'scissors', 'rock']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lizard', 'spock', 'other', 'paper', 'scissors', 'rock']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = os.listdir(train_dir)\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a train/validation split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for c in categories:\n",
    "    os.makedirs(val_dir + c, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_val_split(p):\n",
    "    \"\"\"\n",
    "    Move random images of each category from train to val.\n",
    "    p is the percentage of images to move, e.g.\n",
    "    p == 0.2 will move 20% of each category to val.\n",
    "    \"\"\"\n",
    "    for c in categories:\n",
    "        file_names = os.listdir(train_dir + c)\n",
    "        permutation = np.random.permutation(file_names)\n",
    "        for i in range(int(len(file_names) * p)):\n",
    "            file_path = os.path.join(c, permutation[i])\n",
    "            os.rename(os.path.join(train_dir, file_path), \n",
    "                      os.path.join(val_dir, file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# only do this once\n",
    "make_val_split(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, Dropout, Activation, GlobalAveragePooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SqueezeNet but replace its top layers (the classification layers) to classify between 'rock', 'paper', 'scissors', 'lizard', 'spock' and 'other' and not between the 1000 ImageNet classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/jeremykawahara/keras-squeezenet/raw/master/weights/squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "2998272/3032184 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "base_model = SqueezeNet(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = Dropout(0.5, name='drop9')(x)\n",
    "x = Convolution2D(len(categories), (1, 1), padding='valid', name='conv10')(x)\n",
    "x = Activation('relu', name='relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "predictions = Activation('softmax', name='loss')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, generator=ImageDataGenerator(), shuffle=True,\n",
    "                batch_size=batch_size, class_mode='categorical', target_size=(227,227)):\n",
    "    return generator.flow_from_directory(dirname, shuffle=shuffle, batch_size=batch_size,\n",
    "                                 class_mode=class_mode, target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1301 images belonging to 6 classes.\n",
      "Found 323 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(train_dir)\n",
    "val_batches = get_batches(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = train_batches.samples\n",
    "num_val = val_batches.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(model, epochs):\n",
    "    model.fit_generator(train_batches, \n",
    "                        steps_per_epoch=num_train // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_batches,\n",
    "                        validation_steps=num_val // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 49s - loss: 1.9781 - acc: 0.3270 - val_loss: 1.5053 - val_acc: 0.4258\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 48s - loss: 1.5591 - acc: 0.3338 - val_loss: 1.5009 - val_acc: 0.2539\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 48s - loss: 1.4380 - acc: 0.3636 - val_loss: 1.5426 - val_acc: 0.3047\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 48s - loss: 1.5838 - acc: 0.2872 - val_loss: 1.5208 - val_acc: 0.4023\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 48s - loss: 1.4855 - acc: 0.3527 - val_loss: 1.4059 - val_acc: 0.4922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b1ca16898>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 53s - loss: 1.3813 - acc: 0.4422 - val_loss: 1.2947 - val_acc: 0.4727\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 44s - loss: 1.3131 - acc: 0.4481 - val_loss: 1.1375 - val_acc: 0.5195\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 0.1\n",
    "fit(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 49s - loss: 1.2365 - acc: 0.4653 - val_loss: 1.5440 - val_acc: 0.4102\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 0.01\n",
    "fit(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 49s - loss: 1.3378 - acc: 0.4472 - val_loss: 1.1216 - val_acc: 0.6250\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 48s - loss: 1.1095 - acc: 0.5644 - val_loss: 0.8856 - val_acc: 0.6484\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 48s - loss: 0.8915 - acc: 0.6411 - val_loss: 0.9533 - val_acc: 0.5586\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "fit(model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 49s - loss: 0.8998 - acc: 0.6612 - val_loss: 0.7066 - val_acc: 0.7656\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 52s - loss: 0.5834 - acc: 0.7977 - val_loss: 0.4073 - val_acc: 0.9062\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 44s - loss: 1.2958 - acc: 0.6536 - val_loss: 1.1508 - val_acc: 0.5234\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "fit(model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 49s - loss: 1.0495 - acc: 0.6164 - val_loss: 0.7838 - val_acc: 0.7812\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 48s - loss: 0.7439 - acc: 0.7311 - val_loss: 0.7127 - val_acc: 0.7539\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 52s - loss: 0.6578 - acc: 0.7625 - val_loss: 0.5134 - val_acc: 0.8281\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-6\n",
    "fit(model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 49s - loss: 0.3665 - acc: 0.8905 - val_loss: 0.2443 - val_acc: 0.9297\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 48s - loss: 0.2053 - acc: 0.9223 - val_loss: 0.0870 - val_acc: 0.9727\n",
      "Epoch 3/10\n",
      " 1/10 [==>...........................] - ETA: 44s - loss: 0.0871 - acc: 0.9688"
     ]
    }
   ],
   "source": [
    "fit(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.ckpt'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = K.get_session()\n",
    "saver = tf.train.Saver()\n",
    "saver.save(session, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: dump_checkpoint_vars.py [-h] --checkpoint_file CHECKPOINT_FILE\n",
      "                               --output_dir OUTPUT_DIR\n",
      "                               [--remove_variables_regex REMOVE_VARIABLES_REGEX]\n",
      "dump_checkpoint_vars.py: error: the following arguments are required: --checkpoint_file, --output_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run dump_checkpoint_vars.py --output-dir=deeplearn-checkpoint --checkpoint-file=data/models/model.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
